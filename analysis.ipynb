{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "This Jupyter Notebook contains code to create all tables and figures used in the research. Run the first cell at the beginning because it contains code necessary \n",
    "to run all the bottom cells. Most cells can then be autonomously run to create the tables or figures indicated on the first line. If a cell is dependent on another, \n",
    "it says so in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option('display.min_rows', 400)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 75\n",
    "\n",
    "# Convert the 'created_at' strings to datetime and then ISO calendar values. The ISO calendar is based on years, weeks and days.\n",
    "# Then update the 'created_at' column with simple strings representing the year and week, e.g. '2018-05', and exclude potential tweets from outside our period.\n",
    "tweets = pd.read_feather('data/final_tweets.feather')\n",
    "year_week = pd.to_datetime(tweets.created_at.values, dayfirst = True).isocalendar()\n",
    "tweets['created_at'] = [f'{year_week.iat[idx, 0]}-{str(year_week.iat[idx, 1]).zfill(2)}' for idx in range(len(year_week))]\n",
    "tweets = tweets[tweets.created_at.isin(['2019-48', '2019-49', '2019-50', '2019-51', '2019-52']) == False]\n",
    "\n",
    "# Create a column in the tweets dataframe that indicates whether a given tweet was made before or after the beginning of FFF protests.\n",
    "pre = sorted(tweets.created_at.unique())[:38]\n",
    "tweets['period'] = ['Pre FFF' if row.created_at in pre else 'Post FFF' for row in tweets.itertuples()]\n",
    "\n",
    "# Import and adapt the companies dataframe, define variables used in multiple subsequent cells.\n",
    "companies = pd.read_csv('data/Forbes_global_2000_2019.csv')\n",
    "companies = companies[companies['Continent'] == 'Europe']\n",
    "unique_countries = np.append(companies.Country.unique(), 'Total')\n",
    "for idx, ele in enumerate(unique_countries):\n",
    "    if unique_countries[idx] == 'United Kingdom':\n",
    "        unique_countries[idx] = 'UK'\n",
    "    elif unique_countries[idx] == 'Czech Republic':\n",
    "        unique_countries[idx] = 'Czechia'\n",
    "\n",
    "# Define rows in tables to be shaded grey or colored red.\n",
    "idx_grey = pd.IndexSlice\n",
    "slice_grey = idx_grey[::2, :]\n",
    "idx_no_twitter = pd.IndexSlice\n",
    "slice_no_twitter = idx_no_twitter[companies['Twitter ID'] == 'No Twitter', :]\n",
    "\n",
    "topic_names = ['Non-category', 'Health', 'Cars', 'Sports', 'Diversity', 'Financial results', 'Economics', 'Financial services', 'Customer service', \\\n",
    "                'Food & Holidays', 'Luxury', 'Travel', 'IT infrastructure', 'Future mobility', 'Sustainability', 'Artificial Intelligence', 'Innovation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualised Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagrams import Cluster, Diagram\n",
    "from diagrams.saas.social import Twitter\n",
    "from diagrams.custom import Custom\n",
    "\n",
    "graph_attr = {\n",
    "    \"bgcolor\": \"transparent\"\n",
    "}\n",
    "\n",
    "with Diagram('', filename='visualised_approach', show=False, graph_attr=graph_attr, direction='LR'):\n",
    "    tw = Twitter('Input Tweet')\n",
    "    topics = Custom('Topics', './icons/boxes.png')\n",
    "    \n",
    "    with Cluster('Preprocess', graph_attr=graph_attr):\n",
    "        cleaning = Custom('Cleaning', './icons/clean.png')\n",
    "        translating = Custom('Translating', './icons/helsinki_nlp.png')\n",
    "        cleaning >> translating\n",
    "    \n",
    "    with Cluster('Embedding & Clustering', graph_attr=graph_attr):\n",
    "        embedding = Custom('Embedding', './icons/hugging_face.png')\n",
    "        reducing = Custom('Dimensionality Reduction', './icons/umap.png')\n",
    "        clustering = Custom('Clustering', './icons/hdbscan.png')\n",
    "        embedding >> reducing >> clustering\n",
    "\n",
    "    tw >> cleaning >> embedding >> topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forbes Global 2000 European companies complete and small table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 Forbes Global 2000 European companies complete table\n",
    "companies.style.hide(['Forbes Webpage', 'Profits as % of Assets', 'Profits as % of Revenue', 'Continent', 'Headquarters'], axis = 'columns')\\\n",
    "                .format(precision = 2)\\\n",
    "                .set_properties(**{'background-color': '#e6e6e3'}, subset = slice_grey)\\\n",
    "                .set_properties(**{'background-color': '#ff7f7f'}, subset = slice_no_twitter)\\\n",
    "                .set_table_styles([\n",
    "    {'selector': '', 'props': 'border-spacing: 0px; border-bottom: 2px solid black; font-size: 8pt; padding-bottom: 5px;'},\n",
    "    {'selector': 'th.col_heading', 'props': 'font-family: Helvetica Neue; font-weight: bold; text-align: left; border-top: 2px solid black; border-bottom: 1px solid black; padding-top: 10px; padding-bottom: 5px;'},\n",
    "    {'selector': 'th.row_heading', 'props': 'font-family: Helvetica Neue;'},\n",
    "    {'selector': 'td', 'props': 'border-width: 0px; font-family: Helvetica Neue; text-align: left;'}])\\\n",
    "                .to_html(buf = f'{os.getcwd()}/forbes_complete.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 Forbes Global 2000 European companies small table\n",
    "companies_sample = companies.sample(10, random_state = 123)\n",
    "companies_sample.style.hide()\\\n",
    "                .hide(['Forbes Webpage', 'Profits as % of Assets', 'Profits as % of Revenue', 'Continent', 'Headquarters'], axis = 'columns')\\\n",
    "                .format(precision = 2)\\\n",
    "                .set_properties(**{'background-color': '#e6e6e3'}, subset = slice_grey)\\\n",
    "                .set_properties(**{'background-color': '#ff7f7f'}, subset = slice_no_twitter)\\\n",
    "                .set_table_styles([\n",
    "    {'selector': '', 'props': 'border-spacing: 0px; border-bottom: 2px solid black; font-size: 8pt; padding-bottom: 5px;'},\n",
    "    {'selector': 'th', 'props': 'font-family: Helvetica Neue; font-weight: bold; text-align: left; border-top: 2px solid black; border-bottom: 1px solid black; padding-top: 10px; padding-bottom: 5px;'},\n",
    "    {'selector': 'td', 'props': 'border-width: 0px; font-family: Helvetica Neue; text-align: left;'}])\\\n",
    "                .to_html(buf = f'{os.getcwd()}/forbes_small.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fridays for Future table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fff_18 = pd.read_csv('data/FFF_global_2018.csv')\n",
    "fff_18 = fff_18.set_index('Unnamed: 0')\n",
    "fff_18.index.name = None\n",
    "fff_18.columns = pd.to_datetime(fff_18.columns.values, dayfirst = True).isocalendar()\n",
    "fff_18 = fff_18.filter(items = unique_countries, axis = 0)\n",
    "fff_18 = fff_18.groupby(fff_18.columns, axis = 1).agg(lambda x: x.apply(lambda y: sum([l for l in y if str(l) != \"nan\"]), axis = 1))\n",
    "\n",
    "fff_19 = pd.read_csv('data/FFF_global_2019.csv')\n",
    "fff_19 = fff_19.set_index('Unnamed: 0')\n",
    "fff_19.index.name = None\n",
    "fff_19 = fff_19.filter(items = unique_countries, axis = 0).drop(['01.12.19', '08.12.19', '15.12.19', '22.12.19', '29.12.19', '05.01.20'], axis = 1)\n",
    "fff_19.columns = pd.to_datetime(fff_19.columns.values, dayfirst = True).isocalendar()\n",
    "fff_19 = fff_19.groupby(fff_19.columns, axis = 1).agg(lambda x: x.apply(lambda y: sum([l for l in y if str(l) != \"nan\"]), axis = 1))\n",
    "\n",
    "fff = pd.concat([fff_18, fff_19], axis = 1)\n",
    "fff = fff.groupby(fff.columns, axis = 1).agg(lambda x: x.apply(lambda y: sum([l for l in y if str(l) != \"nan\"]), axis = 1))\n",
    "fff.columns = ['-'.join(tuple(str(num).zfill(2) for num in tup[:2])) for tup in fff.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fff.style.format(precision = 0)\\\n",
    "            .set_properties(**{'background-color': '#e6e6e3'}, subset = slice_grey)\\\n",
    "            .applymap(lambda v, props='color: rgba(0,0,0,0);': props if v == 0 else None)\\\n",
    "            .set_table_styles([\n",
    "    {'selector': '', 'props': 'border-spacing: 0px; border-top: 2px solid black; border-bottom: 2px solid black; font-size: 6pt; padding-bottom: 5px;'},\n",
    "    {'selector': 'th.col_heading', 'props': 'font-family: Helvetica Neue; font-weight: bold; text-align: left; border-bottom: 1px solid black; padding-top: 10px; padding-bottom: 5px; min-width: 35px;'},\n",
    "    {'selector': 'th.row_heading', 'props': 'font-family: Helvetica Neue;'},\n",
    "    {'selector': 'td', 'props': 'border-width: 0px; font-family: Helvetica Neue; text-align: left;'}])\\\n",
    "            .to_html(buf = f'{os.getcwd()}/fff.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP fire graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.plot\n",
    "import pickle\n",
    "from umap import UMAP\n",
    "\n",
    "if os.path.isfile(f'{(cwd := os.getcwd())}/data/embeddings.pkl'):\n",
    "    with open('data/embeddings.pkl', \"rb\") as fIn:\n",
    "        stored_data = pickle.load(fIn)\n",
    "        embeddings = stored_data['embeddings']\n",
    "\n",
    "umap_embeddings_plot = UMAP(n_components = 2, n_neighbors = 100, min_dist = 0.01, verbose = True, low_memory = True).fit(embeddings)\n",
    "umap.plot.points(umap_embeddings_plot, labels=tweets.topic, theme='fire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.read_csv('data/top_n_words_per_topic.csv', header=None)\n",
    "del topics[0]\n",
    "topics.reindex(columns=range(1, 11))\n",
    "for row in topics.itertuples():\n",
    "    adapted_row = topics.at[row.Index, 1].split('(')\n",
    "    adapted_row.remove('[')\n",
    "    topics.at[row.Index, 1] = [ele.split(',')[0][1:-1] for ele in adapted_row]\n",
    "    for idx in reversed(range(1, 11)):\n",
    "        topics.at[row.Index, idx] = topics.at[row.Index, 1].pop()\n",
    "\n",
    "topics = topics.set_index(pd.Index(range(-1, 16)))\n",
    "topics = topics[sorted(topics.columns)]\n",
    "topics['Topic name'] = topic_names\n",
    "\n",
    "topics.style.format(precision = 0)\\\n",
    "            .set_properties(**{'background-color': '#e6e6e3'}, subset = slice_grey)\\\n",
    "            .applymap(lambda v, props='color: rgba(0,0,0,0);': props if v == 0 else None)\\\n",
    "            .set_table_styles([\n",
    "    {'selector': '', 'props': 'border-spacing: 0px; border-top: 2px solid black; border-bottom: 2px solid black; font-size: 8pt; padding-bottom: 5px;'},\n",
    "    {'selector': 'th.col_heading', 'props': 'font-family: Helvetica Neue; font-weight: bold; text-align: left; border-bottom: 1px solid black; padding-top: 10px; padding-bottom: 5px;'},\n",
    "    {'selector': 'th.row_heading', 'props': 'font-family: Helvetica Neue;'},\n",
    "    {'selector': 'td.data.col10', 'props': 'font-weight: bold;'},\n",
    "    {'selector': 'td', 'props': 'border-width: 0px; font-family: Helvetica Neue; text-align: left;'}])\\\n",
    "            .to_html(buf = f'{os.getcwd()}/topics.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall protests and tweeting\n",
    "This part depends on the 'Fridays for Future table' cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a df that is the basis of our graphs. Its index are all weeks considered and its columns are defined one after the other.\n",
    "general_date = pd.DataFrame(tweets.groupby('created_at').size(), columns=['total_tweets'])\n",
    "general_date.index.rename('week', inplace=True)\n",
    "general_date['sustainability_tweets'] = tweets.loc[tweets['topic'] == 13].groupby('created_at').size()\n",
    "general_date['sustainability_share'] = general_date['sustainability_tweets'] / general_date['total_tweets']\n",
    "general_date['total_protesters'] = fff.iloc[-1]\n",
    "general_date['total_protesters'] = general_date['total_protesters'].fillna(0).astype('Int64')\n",
    "general_date = general_date.reset_index()\n",
    "general_date['week'] = general_date['week'].astype(str)\n",
    "\n",
    "general_pre_fff_median = general_date.iloc[:38]['sustainability_share'].median().round(3)\n",
    "general_post_fff_median = general_date.iloc[38:]['sustainability_share'].median().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(general_date, x=\"week\", y=\"sustainability_share\", height=500, width=1000, color_discrete_sequence=['black'])\\\n",
    "    .update_layout(title=dict(text='Share of corporate tweets related to sustainability', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    xaxis_title=dict(text='Week', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    xaxis=dict(tickfont=dict(family='Helvetica Neue', color='black'), type='category'),\n",
    "                    yaxis_title=dict(text='Percentage of tweets', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    yaxis=dict(tickfont=dict(family='Helvetica Neue', color='black'), tickformat='.0%'),\n",
    "                    autosize=False,\n",
    "                    plot_bgcolor='#e6e6e3')\\\n",
    "    .add_shape(type=\"line\", x0=0, y0=general_pre_fff_median, x1='2018-33', y1=general_pre_fff_median, line=dict(color='#C84B31', dash=\"dashdot\"))\\\n",
    "    .add_shape(type=\"line\", x0='2018-35', y0=general_post_fff_median, x1='2019-47', y1=general_post_fff_median, line=dict(color='#C84B31', dash=\"dashdot\"))\\\n",
    "    .add_annotation(x='2019-37', y=0.065, text=\"Post FFF median\", font=dict(family='Helvetica Neue', color='#C84B31'), showarrow=False)\\\n",
    "    .add_annotation(x='2018-04', y=0.057, text=\"Pre FFF median\", font=dict(family='Helvetica Neue', color='#C84B31'), showarrow=False)\\\n",
    "    .add_vrect(x0=\"2018-34\", x1=\"2018-35\", annotation_text=\"FFF protests start\", annotation_font_family='Helvetica Neue', annotation_position=\"top left\",\n",
    "                fillcolor=\"black\", opacity=0.25, line_width=0, annotation=dict(font_color='black'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(general_date, x=\"week\", y=\"total_protesters\", height=500, width=1000)\\\n",
    "    .update_layout(title=dict(text='FFF protesters in selected European countries per week', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    xaxis_title=dict(text='Week', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    xaxis=dict(tickfont=dict(family='Helvetica Neue', color='black'), type='category'),\n",
    "                    yaxis_title=dict(text='Number of protesters', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    yaxis=dict(tickfont=dict(family='Helvetica Neue', color='black')),\n",
    "                    autosize=False,\n",
    "                    plot_bgcolor='#e6e6e3')\\\n",
    "    .add_vrect(x0=\"2018-34\", x1=\"2018-35\", annotation_text=\"FFF protests start\", annotation_font_family='Helvetica Neue', annotation_position=\"top left\",\n",
    "                fillcolor=\"black\", opacity=0.25, line_width=0, annotation=dict(font_color='black'))\\\n",
    "    .update_traces(line_color='black')\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "r, p = pearsonr(general_date['sustainability_share'], general_date['total_protesters'])\n",
    "print('Pearsons correlation: %.3f' % r)\n",
    "print('The p-value is: %.20f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2B and B2C differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is necessary for all other cells in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column in the tweets dataframe with the respective company name.\n",
    "ids = [id[1:] for id in companies['Twitter ID'].values]\n",
    "handle_to_name = pd.Series(companies.Company.values, index=ids).to_dict()\n",
    "tweets['company'] = [handle_to_name[handle] for handle in tweets.screen_handle.values]\n",
    "\n",
    "# All industries in the Materials and Industrials sectors minus 'Airline', 'Conglomerate' and 'Air Courier'\n",
    "b2b_industries = ['Iron & Steel', 'Construction Services', 'Diversified Chemicals', 'Diversified Metals & Mining', \n",
    "                    'Other Transportation', 'Electrical Equipment', 'Trucking', 'Paper & Paper Products',\n",
    "                    'Heavy Equipment', 'Specialized Chemicals', 'Aerospace & Defense', 'Construction Materials', \n",
    "                    'Other Industrial Equipment', 'Aluminum']\n",
    "\n",
    "# All industries in the Consumer Discretionary and Consumer Staples sectors minus 'Business and Personal Services', 'Advertising'\n",
    "b2c_industries = ['Beverages', 'Food Retail', 'Apparel/Accessories', 'Household/Personal Care',\n",
    "                    'Auto & Truck Manufacturers', 'Food Processing', 'Auto & Truck Parts', 'Hotels & Motels',\n",
    "                    'Household Appliances', 'Department Stores', 'Specialty Stores', 'Apparel/Footwear Retail', \n",
    "                    'Broadcasting & Cable', 'Furniture & Fixtures', 'Printing & Publishing', 'Consumer Electronics', \n",
    "                    'Tobacco', 'Restaurants', 'Home Improvement Retail']\n",
    "\n",
    "# Create a column in the tweets dataframe indicating whether a given tweet stems from a b2b, b2c or other company.\n",
    "b2b_companies = companies.loc[companies['Industry'].isin(b2b_industries)].Company.values\n",
    "b2c_companies = companies.loc[companies['Industry'].isin(b2c_industries)].Company.values\n",
    "context = []\n",
    "for company in tweets['company']:\n",
    "    if company in b2b_companies:\n",
    "        context.append('B2B')\n",
    "    elif company in b2c_companies:\n",
    "        context.append('B2C')\n",
    "    else:\n",
    "        context.append('other')\n",
    "\n",
    "tweets['context'] = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2b_b2c_test = pd.DataFrame(tweets.groupby(['context', 'company']).size(), columns=['total_tweets']).reset_index()\n",
    "b2b_b2c_test = b2b_b2c_test.loc[b2b_b2c_test['context'] != 'other']\n",
    "\n",
    "sus_tweets = []\n",
    "b2b_b2c_sus_tweets = pd.DataFrame(tweets.groupby(['context', 'company', 'topic']).size()).reset_index()\n",
    "b2b_b2c_sus_tweets = b2b_b2c_sus_tweets[b2b_b2c_sus_tweets['topic'] == 13]\n",
    "for company in b2b_b2c_test.company:\n",
    "    try:\n",
    "        num_of_sus_tweets = int(b2b_b2c_sus_tweets[b2b_b2c_sus_tweets['company'] == company][0])\n",
    "        sus_tweets.append(num_of_sus_tweets)\n",
    "    except TypeError:\n",
    "        sus_tweets.append(0)\n",
    "\n",
    "b2b_b2c_test['sustainability_tweets'] = sus_tweets\n",
    "b2b_b2c_test['sustainability_share'] = (b2b_b2c_test['sustainability_tweets'] / b2b_b2c_test['total_tweets']).round(3)\n",
    "\n",
    "summary = b2b_b2c_test[b2b_b2c_test['context'] == 'B2B']['sustainability_tweets'].describe().to_frame()\n",
    "summary = summary.rename(columns={'sustainability_tweets': 'B2B absolute sustainability tweets'})\n",
    "summary['B2B relative sustainability tweets'] = b2b_b2c_test[b2b_b2c_test['context'] == 'B2B']['sustainability_share'].describe().to_frame().sustainability_share\n",
    "summary['B2C absolute sustainability tweets'] = b2b_b2c_test[b2b_b2c_test['context'] == 'B2C']['sustainability_tweets'].describe().to_frame().sustainability_tweets\n",
    "summary['B2C relative sustainability tweets'] = b2b_b2c_test[b2b_b2c_test['context'] == 'B2C']['sustainability_share'].describe().to_frame().sustainability_share\n",
    "summary['B2B absolute sustainability tweets'] = summary['B2B absolute sustainability tweets'].astype(int)\n",
    "summary['B2C absolute sustainability tweets'] = summary['B2C absolute sustainability tweets'].astype(int)\n",
    "\n",
    "summary.style.format(precision = 3)\\\n",
    "            .set_properties(**{'background-color': '#e6e6e3'}, subset = slice_grey)\\\n",
    "            .set_table_styles([\n",
    "    {'selector': '', 'props': 'border-spacing: 0px; border-top: 2px solid black; border-bottom: 2px solid black; font-size: 6pt; padding-bottom: 5px;'},\n",
    "    {'selector': 'th.col_heading', 'props': 'font-family: Helvetica Neue; font-weight: bold; text-align: left; border-bottom: 1px solid black; padding-top: 10px; padding-bottom: 5px; padding-left: 10px; min-width: 35px;'},\n",
    "    {'selector': 'th.row_heading', 'props': 'font-family: Helvetica Neue;'},\n",
    "    {'selector': 'td', 'props': 'border-width: 0px; font-family: Helvetica Neue; text-align: left; text-align: center;'}])\\\n",
    "            .to_html(buf = f'{os.getcwd()}/b2b_b2c_summary.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_date_table(context):\n",
    "    context_date_table = pd.DataFrame(tweets.loc[tweets['context'] == context].groupby('created_at').size(), columns=['total_tweets'])\n",
    "    context_date_table.index.rename('week', inplace=True)\n",
    "    context_date_table['sustainability_tweets'] = tweets.loc[(tweets['context'] == context) & (tweets['topic'] == 13)].groupby('created_at').size()\n",
    "    context_date_table['sustainability_share'] = context_date_table['sustainability_tweets'] / context_date_table['total_tweets']\n",
    "    context_date_table.reset_index(inplace=True)\n",
    "    context_date_table['context'] = context\n",
    "    context_date_table['week'] = context_date_table['week'].astype(str)\n",
    "    pre_fff_median = context_date_table.iloc[:38]['sustainability_share'].median().round(3)\n",
    "    post_fff_median = context_date_table.iloc[38:]['sustainability_share'].median().round(3)\n",
    "\n",
    "    return context_date_table, pre_fff_median, post_fff_median\n",
    "\n",
    "b2b_date, b2b_pre_fff_median, b2b_post_fff_median = create_context_date_table('B2B')\n",
    "b2c_date, b2c_pre_fff_median, b2c_post_fff_median = create_context_date_table('B2C')\n",
    "b2b_b2c_date = pd.merge(b2b_date, b2c_date, how='outer')\n",
    "\n",
    "px.line(b2b_b2c_date, x=\"week\", y=\"sustainability_share\", color='context', color_discrete_sequence=['#346751', '#C84B31'], height=500, width=1000)\\\n",
    "    .update_layout(title=dict(text=\"B2B and B2C companies' overall shares of sustainability tweets per week\", font=dict(family='Helvetica Neue', color='black')),\n",
    "                    xaxis_title=dict(text='Week', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    xaxis=dict(tickfont=dict(family='Helvetica Neue', color='black'), type='category'),\n",
    "                    yaxis_title=dict(text='Share of sustainability tweets', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    yaxis=dict(tickfont=dict(family='Helvetica Neue', color='black')),\n",
    "                    autosize=False,\n",
    "                    plot_bgcolor='#e6e6e3',\n",
    "                    legend_title=dict(text='Context', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    legend=dict(font=dict(color='black')))\\\n",
    "    .add_shape(type=\"line\", x0=0, y0=b2b_pre_fff_median, x1='2018-34', y1=b2b_pre_fff_median, line=dict(color=\"black\", dash=\"dashdot\"))\\\n",
    "    .add_shape(type=\"line\", x0='2018-35', y0=b2b_post_fff_median, x1='2019-47', y1=b2b_post_fff_median, line=dict(color=\"black\", dash=\"dashdot\"))\\\n",
    "    .add_shape(type=\"line\", x0=0, y0=b2c_pre_fff_median, x1='2018-34', y1=b2c_pre_fff_median, line=dict(color=\"black\", dash=\"dashdot\"))\\\n",
    "    .add_shape(type=\"line\", x0='2018-35', y0=b2c_post_fff_median, x1='2019-47', y1=b2c_post_fff_median, line=dict(color=\"black\", dash=\"dashdot\"))\\\n",
    "    .add_annotation(x='2019-37', y=0.105, text=\"Post FFF B2B median\", font=dict(family='Helvetica Neue', color='black'), showarrow=False)\\\n",
    "    .add_annotation(x='2018-04', y=0.092, text=\"Pre FFF B2B median\", font=dict(family='Helvetica Neue', color='black'), showarrow=False)\\\n",
    "    .add_annotation(x='2019-37', y=0.026, text=\"Post FFF B2C median\", font=dict(family='Helvetica Neue', color='black'), showarrow=False)\\\n",
    "    .add_annotation(x='2018-04', y=0.026, text=\"Pre FFF B2C median\", font=dict(family='Helvetica Neue', color='black'), showarrow=False)\\\n",
    "    .add_vrect(x0=\"2018-34\", x1=\"2018-35\", annotation_text=\"FFF protests start\", annotation_font_family='Helvetica Neue', annotation_position=\"top left\", \n",
    "                fillcolor=\"black\", opacity=0.25, line_width=0, annotation=dict(font_color='black'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2b_b2c_count = pd.DataFrame(tweets.groupby(['context', 'period', 'topic']).size()).reset_index()\n",
    "b2b_b2c_count = b2b_b2c_count.loc[b2b_b2c_count['context'] != 'other']\n",
    "b2b_b2c_count['topic'] = b2b_b2c_count['topic'].astype(str)\n",
    "newnames = {str(x):y for x,y in zip(sorted(tweets.topic.unique().tolist()), topic_names)}\n",
    "\n",
    "px.bar(b2b_b2c_count, x=0, y='context', color=\"topic\", facet_row='period', width=1100, category_orders={'context': ['B2B', 'B2C'], 'period': ['Pre FFF', 'Post FFF']}, \n",
    "                        color_discrete_sequence=px.colors.qualitative.T10, orientation='h')\\\n",
    "    .update_layout(xaxis_title=dict(text='Number of tweets', font=dict(family='Helvetica Neue', color='black')),\n",
    "                    xaxis=dict(tickfont=dict(family='Helvetica Neue', color='black')),\n",
    "                    autosize=False,\n",
    "                    plot_bgcolor='#e6e6e3',\n",
    "                    legend_title=dict(text=''),\n",
    "                    legend=dict(orientation='h', yanchor='bottom', y=1, xanchor='right', x=0.9, font=dict(family='Helvetica Neue', color='black')))\\\n",
    "    .update_yaxes(tickfont=dict(family='Helvetica Neue', color='black'), title=dict(text='', font=dict(family='Helvetica Neue', color='black')))\\\n",
    "    .for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1], textangle=0, font=dict(family='Helvetica Neue', color='black')))\\\n",
    "    .for_each_trace(lambda t: t.update(name = newnames[t.name]))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "b2b_date = b2b_date[38:]\n",
    "b2b_date['protesters'] = stats.zscore(fff.iloc[-1].astype(int).tolist())\n",
    "b2b_date['sustainability_share'] = stats.zscore(b2b_date['sustainability_share'])\n",
    "\n",
    "b2c_date = b2c_date[38:]\n",
    "b2c_date['protesters'] = stats.zscore(fff.iloc[-1].astype(int).tolist())\n",
    "b2c_date['sustainability_share'] = stats.zscore(b2c_date['sustainability_share'])\n",
    "\n",
    "reg_b2b = sm.ols(formula='sustainability_share ~ protesters', data=b2b_date).fit()\n",
    "print(reg_b2b.summary())\n",
    "reg_b2c = sm.ols(formula='sustainability_share ~ protesters', data=b2c_date).fit()\n",
    "print(reg_b2c.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borders, a transnational movement and multinational companies\n",
    "The following cells are dependent on the first cell in the 'B2B and B2C differences', the first cell in the 'Overall protests and tweeting' and the first cell in the 'Fridays for Future table' sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_country_dict = {company: country for company, country in zip(companies['Company'], companies['Country'])}\n",
    "tweets['country'] = [company_country_dict[row.company] for row in tweets.itertuples()]\n",
    "top_countries = [country for country, no_of_companies in companies.groupby('Country').size().iteritems() if no_of_companies > 25]\n",
    "tweets_by_top_countries = tweets[tweets.country.isin(top_countries)]\n",
    "tweets_by_top_countries_13 = tweets[(tweets.country.isin(top_countries)) & (tweets['topic'] == 13)]\n",
    "\n",
    "country_date = pd.DataFrame(tweets_by_top_countries.groupby(['created_at', 'country']).size(), columns=['total_tweets']).reset_index()\n",
    "temp_df = pd.DataFrame(tweets_by_top_countries_13.groupby(['created_at', 'country']).size(), columns=['sust_tweets']).reset_index()\n",
    "country_date = pd.merge(country_date, temp_df, on = ['created_at', 'country'], how = 'outer')\n",
    "country_date.fillna(1, inplace=True)\n",
    "country_date['sust_tweets'] = country_date['sust_tweets'].astype(int)\n",
    "country_date['sust_share'] = country_date['sust_tweets'] / country_date['total_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(country_date, x=\"created_at\", y=\"sust_share\", color='country', color_discrete_sequence= ['#7A7A78', '#1C684E', '#8DB3A7', '#EC9F92', '#D94025', '#732719'],\n",
    "                        facet_col='country', facet_col_wrap=3, facet_row_spacing=0.12, width=1300, height=900)\\\n",
    "    .update_layout(plot_bgcolor='#e6e6e3')\\\n",
    "    .update_traces(showlegend=False)\\\n",
    "    .update_xaxes(tickfont=dict(family='Helvetica Neue', color='black'), type='category')\\\n",
    "    .update_xaxes(title=dict(text='Week', font=dict(family='Helvetica Neue', color='black')), row=1)\\\n",
    "    .update_yaxes(tickfont=dict(family='Helvetica Neue', color='black'))\\\n",
    "    .update_yaxes(title=dict(text='Share of sustainability tweets', font=dict(family='Helvetica Neue', color='black')), col=1)\\\n",
    "    .for_each_xaxis(lambda yaxis: yaxis.update(showticklabels=True))\\\n",
    "    .for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1], textangle=0, font=dict(family='Helvetica Neue', color='black')))\\\n",
    "    .add_shape(type=\"line\", x0=0, y0=general_pre_fff_median, x1='2018-33', y1=general_pre_fff_median, line=dict(color='black', dash=\"dashdot\"), row='all', col='all')\\\n",
    "    .add_shape(type=\"line\", x0='2018-35', y0=general_post_fff_median, x1='2019-47', y1=general_post_fff_median, line=dict(color='black', dash=\"dashdot\"), row='all', col='all')\\\n",
    "    .add_annotation(x='2018-14', y=0.062, text=\"European pre FFF median\", font=dict(family='Helvetica Neue', color='black', size=10), showarrow=False, row='all', col='all')\\\n",
    "    .add_annotation(x='2019-20', y=0.07, text=\"European post FFF median\", font=dict(family='Helvetica Neue', color='black', size=10), showarrow=False, row='all', col='all')\\\n",
    "    .add_vrect(x0=\"2018-34\", x1=\"2018-35\", annotation_text=\"FFF protests start\", annotation_font_family='Helvetica Neue', annotation_position=\"top left\", \n",
    "                fillcolor=\"black\", opacity=0.25, line_width=0, annotation=dict(font_color='black'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = pd.DataFrame(columns=['Country', 'Coefficient', 'Standard Deviation', 't-Value', 'p-Value', 'F-Value', 'F-p-Value', 'R-Squared'])\n",
    "for country in top_countries:\n",
    "    temp_df = country_date[country_date['country'] == country][38:]\n",
    "    temp_df['protesters'] = stats.zscore(fff.iloc[-1].astype(int).tolist())\n",
    "    temp_df['sust_share'] = stats.zscore(temp_df['sust_share'])\n",
    "    reg_temp = sm.ols(formula='sust_share ~ protesters', data=temp_df).fit()\n",
    "    coef = reg_temp.params[1]\n",
    "    if 0.01 < reg_temp.pvalues[1] < 0.05:\n",
    "        coef = f'{coef:.3f}*'\n",
    "    elif 0.001 < reg_temp.pvalues[1] < 0.01:\n",
    "        coef = f'{coef:.3f}**'\n",
    "    elif reg_temp.pvalues[1] < 0.001:\n",
    "        coef = f'{coef:.3f}***'\n",
    "    else:\n",
    "        coef = f'{coef:.3f}'\n",
    "    reg_df.loc[len(reg_df.index)] = {'Country': country,\n",
    "                                        'Coefficient': coef,\n",
    "                                        'Standard Deviation': reg_temp.bse[1],\n",
    "                                        't-Value': reg_temp.tvalues[1],\n",
    "                                        'p-Value': reg_temp.pvalues[1],\n",
    "                                        'F-Value': reg_temp.fvalue,\n",
    "                                        'F-p-Value': reg_temp.f_pvalue,\n",
    "                                        'R-Squared': reg_temp.rsquared}\n",
    "\n",
    "reg_df.set_index('Country', inplace=True)\n",
    "reg_df.index.name = None\n",
    "reg_df.style.format(precision=3)\\\n",
    "            .set_properties(**{'background-color': '#e6e6e3'}, subset = slice_grey)\\\n",
    "            .set_table_styles([\n",
    "    {'selector': '', 'props': 'border-spacing: 0px; border-top: 2px solid black; border-bottom: 2px solid black; font-size: 6pt; padding-bottom: 5px;'},\n",
    "    {'selector': 'th.col_heading', 'props': 'font-family: Helvetica Neue; font-weight: bold; text-align: left; border-bottom: 1px solid black; padding-top: 10px; padding-bottom: 5px; padding-left: 10px; min-width: 35px;'},\n",
    "    {'selector': 'th.row_heading', 'props': 'font-family: Helvetica Neue;'},\n",
    "    {'selector': 'td', 'props': 'border-width: 0px; font-family: Helvetica Neue; text-align: left; text-align: center;'}])\\\n",
    "            .to_html(buf = f'{os.getcwd()}/countries_reg.html')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
